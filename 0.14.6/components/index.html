
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Component Configuration</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/banner.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Server Configuration" href="../config/" />
    <link rel="prev" title="Training Data Format" href="../dataformat/" />

 <!-- Google Tag Manager -->
    <script type="opt-in" data-type="application/javascript" data-name="googletagmanager">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-MMHSZCS');</script>
    <!-- End Google Tag Manager -->
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
  <meta itemprop="image" content="https://rasa.com/assets/img/facebook-og.png">
  <meta property="og:title" content="Component Configuration" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://rasa.com/assets/img/facebook-og.png" />
  <meta property="og:url" content="https://rasa.com/docs/nlu/components" />
  
    <meta name="description" content="Understanding a Rasa NLU Pipeline" />
    <meta itemprop="description" content="Understanding a Rasa NLU Pipeline">
    <meta name="twitter:description" content="Understanding a Rasa NLU Pipeline" />
    <meta property="og:description" content="Understanding a Rasa NLU Pipeline" />
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Rasa_HQ">
  <meta name="twitter:title" content="Component Configuration">
  <meta name="twitter:creator" content="@Rasa_HQ">
  <meta name="twitter:image" content="https://rasa.com/assets/img/facebook-og.png">

  <link rel="stylesheet" href="../_static/xq-light.css" type="text/css" />
  <link rel="stylesheet" href="../_static/fontawesome/css/fontawesome-all.css" type="text/css" />
  <script defer type="text/javascript" src="../_static/config.js"></script>
  <script defer type="text/javascript" src="../_static/klaro.js"></script>
  <script type="text/javascript" src="https://storage.googleapis.com/docs-theme/clipboard.min.js"></script>
  
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />


  </head><body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe data-name="googletagmanager" data-src="https://www.googletagmanager.com/ns.html?id=GTM-MMHSZCS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<div class="nav-top">
  <div class="nav-container">
    <a href="/docs" class="brand-link">
        <h1 class="brand">
            <img src="../_static/rasa_logo.svg" width="80px" height="40px" title="Rasa logo" alt="Rasa logo">
        </h1>
        <span class="logo extension">docs</span>
    </a>

    <ul class="nav">
      <input type="text" class="search" placeholder="Search">
      
        
          <li class="active"><a href=/docs/nlu/>NLU</a></li>
        
      
        
          <li><a href=/docs/core/>Core</a></li>
        
      
        
          <li><a href=/docs/platform/>Platform</a></li>
        
      

      <li>
        <a href="https://github.com/rasaHQ/" target="_blank"><button class="button btn-ghost btn-small"> <i class="fab fa-github"></i>GitHub</button></a>
      </li>

      <li>
        <a href="https://forum.rasa.com" target="_blank"><button class="button btn-small">Ask the Community</button></a>
      </li>

    </ul>
  </div>
</div>

  <div class="sidebar-extended"></div>
  <div class="document">

    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/">Try It Out</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../choosing_pipeline/">Choosing a Rasa NLU Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../languages/">Language Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../entities/">Entity Extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation/">Evaluating and Improving Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fallback/">Confidence and Fallback Intents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/">Frequently Asked Questions</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../dataformat/">Training Data Format</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Component Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config/">Server Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../http/">HTTP API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../persist/">Storing Models in the Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../endpoint_configuration/">Endpoint Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker/">Running in Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../customcomponents/">Custom Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migrations/">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license/">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog/">Change Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support/">Getting Support</a></li>
</ul>

<div class="versions">
    <p class="caption">Versions</p>
    <div class="versions-content">
      <div>
        <span class="current-version">
          viewing: 0.14.6
        </span>
      </div>
      <div class="other-versions">
          <p>tags</p>
          <div class="dropdown-content">
              <a href="../../0.15.1/components/">0.15.1</a>
              <a href="../../0.15.0/components/">0.15.0</a>
              <a href="../../0.14.6/components/">0.14.6</a>
              <a href="../../0.14.5/components/">0.14.5</a>
              <a href="../../0.14.4/components/">0.14.4</a>
              <a href="../../0.14.3/components/">0.14.3</a>
              <a href="../../0.14.2/components/">0.14.2</a>
              <a href="../../0.14.1/components/">0.14.1</a>
              <a href="../../0.14.0/components/">0.14.0</a>
              <a href="../../0.13.8/components/">0.13.8</a>
              <a href="../../0.13.7/components/">0.13.7</a>
              <a href="../../0.13.6/components/">0.13.6</a>
              <a href="../../0.13.5/components/">0.13.5</a>
              <a href="../../0.13.4/components/">0.13.4</a>
              <a href="../../0.13.3/components/">0.13.3</a>
              <a href="../../0.13.2/components/">0.13.2</a>
              <a href="../../0.13.1/index/">0.13.1</a>
              <a href="../../0.13.0/index/">0.13.0</a>
              <a href="../../0.12.4/index/">0.12.4</a>
              <a href="../../0.12.3/index/">0.12.3</a>
              <a href="../../0.12.2/index/">0.12.2</a>
              <a href="../../0.12.1/index/">0.12.1</a>
              <a href="../../0.12.0/index/">0.12.0</a>
              <a href="../../0.11.4/index/">0.11.4</a>
              <a href="../../0.10.6/index/">0.10.6</a>
              <a href="../../0.9.2/index/">0.9.2</a>
              <a href="../../0.8.12/index/">0.8.12</a>
              <a href="../../0.7.4/index/">0.7.4</a>
          </div>
      </div>
    </div>
</div>


        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  


    
    



    <p class="scv-banner"><a href="../../0.15.1/components/"><b>Warning:</b> This document is for an old version of Rasa NLU. The latest version is 0.15.1.</a></p>
<div class="section" id="component-configuration">
<span id="section-pipeline"></span><h1><a class="toc-backref" href="#id3">Component Configuration</a><a class="headerlink" href="#component-configuration" title="Permalink to this headline">¶</a></h1>
<p>This is a reference of the configuration options for every built-in component in
Rasa NLU. If you want to build a custom component, check out <a class="reference internal" href="../customcomponents/#section-customcomponents"><span class="std std-ref">Custom Components</span></a>.</p>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#component-configuration" id="id3">Component Configuration</a><ul>
<li><a class="reference internal" href="#nlp-mitie" id="id4">nlp_mitie</a></li>
<li><a class="reference internal" href="#nlp-spacy" id="id5">nlp_spacy</a></li>
<li><a class="reference internal" href="#intent-featurizer-mitie" id="id6">intent_featurizer_mitie</a></li>
<li><a class="reference internal" href="#intent-featurizer-spacy" id="id7">intent_featurizer_spacy</a></li>
<li><a class="reference internal" href="#intent-featurizer-ngrams" id="id8">intent_featurizer_ngrams</a></li>
<li><a class="reference internal" href="#intent-featurizer-count-vectors" id="id9">intent_featurizer_count_vectors</a></li>
<li><a class="reference internal" href="#intent-classifier-keyword" id="id10">intent_classifier_keyword</a></li>
<li><a class="reference internal" href="#intent-classifier-mitie" id="id11">intent_classifier_mitie</a></li>
<li><a class="reference internal" href="#intent-classifier-sklearn" id="id12">intent_classifier_sklearn</a></li>
<li><a class="reference internal" href="#intent-classifier-tensorflow-embedding" id="id13">intent_classifier_tensorflow_embedding</a></li>
<li><a class="reference internal" href="#intent-entity-featurizer-regex" id="id14">intent_entity_featurizer_regex</a></li>
<li><a class="reference internal" href="#tokenizer-whitespace" id="id15">tokenizer_whitespace</a></li>
<li><a class="reference internal" href="#tokenizer-jieba" id="id16">tokenizer_jieba</a></li>
<li><a class="reference internal" href="#tokenizer-mitie" id="id17">tokenizer_mitie</a></li>
<li><a class="reference internal" href="#tokenizer-spacy" id="id18">tokenizer_spacy</a></li>
<li><a class="reference internal" href="#ner-mitie" id="id19">ner_mitie</a></li>
<li><a class="reference internal" href="#ner-spacy" id="id20">ner_spacy</a></li>
<li><a class="reference internal" href="#ner-synonyms" id="id21">ner_synonyms</a></li>
<li><a class="reference internal" href="#ner-crf" id="id22">ner_crf</a></li>
<li><a class="reference internal" href="#ner-duckling-http" id="id23">ner_duckling_http</a><ul>
<li><a class="reference internal" href="#have-questions-or-feedback" id="id24">Have questions or feedback?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="nlp-mitie">
<span id="id1"></span><h2><a class="toc-backref" href="#id4">nlp_mitie</a><a class="headerlink" href="#nlp-mitie" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE initializer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Initializes mitie structures. Every mitie component relies on this, hence this should be put at the beginning
of every pipeline that uses any mitie components.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">The MITIE library needs a language model file, that <strong>must</strong> be specified in
the configuration:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;nlp_mitie&quot;</span>
  <span class="c1"># language model to load</span>
  <span class="nt">model</span><span class="p">:</span> <span class="s">&quot;data/total_word_feature_extractor.dat&quot;</span>
</pre></div>
</div>
<p class="last">For more information where to get that file from, head over to
<a class="reference internal" href="../installation/#section-backends"><span class="std std-ref">Installation</span></a>.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="nlp-spacy">
<h2><a class="toc-backref" href="#id5">nlp_spacy</a><a class="headerlink" href="#nlp-spacy" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">spacy language initializer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Initializes spacy structures. Every spacy component relies on this, hence this should be put at the beginning
of every pipeline that uses any spacy components.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Language model, default will use the configured language.
If the spacy model to be used has a name that is different from the language tag (<code class="docutils literal notranslate"><span class="pre">&quot;en&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;de&quot;</span></code>, etc.),
the model name can be specified using this configuration variable. The name will be passed to <code class="docutils literal notranslate"><span class="pre">spacy.load(name)</span></code>.</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;nlp_spacy&quot;</span>
  <span class="c1"># language model to load</span>
  <span class="nt">model</span><span class="p">:</span> <span class="s">&quot;en_core_web_md&quot;</span>

  <span class="c1"># when retrieving word vectors, this will decide if the casing</span>
  <span class="c1"># of the word is relevant. E.g. `hello` and `Hello` will</span>
  <span class="c1"># retrieve the same vector, if set to `false`. For some</span>
  <span class="c1"># applications and models it makes sense to differentiate</span>
  <span class="c1"># between these two words, therefore setting this to `true`.</span>
  <span class="nt">case_sensitive</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-mitie">
<h2><a class="toc-backref" href="#id6">intent_featurizer_mitie</a><a class="headerlink" href="#intent-featurizer-mitie" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE intent featurizer</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, used as an input to intent classifiers that need intent features (e.g. <code class="docutils literal notranslate"><span class="pre">intent_classifier_sklearn</span></code>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates feature for intent classification using the MITIE featurizer.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">NOT used by the <code class="docutils literal notranslate"><span class="pre">intent_classifier_mitie</span></code> component. Currently, only <code class="docutils literal notranslate"><span class="pre">intent_classifier_sklearn</span></code> is able
to use precomputed features.</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;intent_featurizer_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-spacy">
<h2><a class="toc-backref" href="#id7">intent_featurizer_spacy</a><a class="headerlink" href="#intent-featurizer-spacy" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">spacy intent featurizer</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing, used as an input to intent classifiers that need intent features (e.g. <code class="docutils literal notranslate"><span class="pre">intent_classifier_sklearn</span></code>)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">Creates feature for intent classification using the spacy featurizer.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-ngrams">
<h2><a class="toc-backref" href="#id8">intent_featurizer_ngrams</a><a class="headerlink" href="#intent-featurizer-ngrams" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Appends char-ngram features to feature vector</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, appends its features to an existing feature vector generated by another intent featurizer</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This featurizer appends character ngram features to a feature vector. During training the component looks for the
most common character sequences (e.g. <code class="docutils literal notranslate"><span class="pre">app</span></code> or <code class="docutils literal notranslate"><span class="pre">ing</span></code>). The added features represent a boolean flag if the
character sequence is present in the word sequence or not.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There needs to be another intent featurizer previous to this one in the pipeline!</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;intent_featurizer_ngrams&quot;</span>
  <span class="c1"># Maximum number of ngrams to use when augmenting</span>
  <span class="c1"># feature vectors with character ngrams</span>
  <span class="nt">max_number_of_ngrams</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-featurizer-count-vectors">
<h2><a class="toc-backref" href="#id9">intent_featurizer_count_vectors</a><a class="headerlink" href="#intent-featurizer-count-vectors" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Creates bag-of-words representation of intent features</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing, used as an input to intent classifiers that
need bag-of-words representation of intent features
(e.g. <code class="docutils literal notranslate"><span class="pre">intent_classifier_tensorflow_embedding</span></code>)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates bag-of-words representation of intent features using
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn’s CountVectorizer</a>.
All tokens which consist only of digits (e.g. 123 and 99 but not a123d) will be assigned to the same feature.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the words in the model language cannot be split by whitespace,
a language-specific tokenizer is required in the pipeline before this component
(e.g. using <code class="docutils literal notranslate"><span class="pre">tokenizer_jieba</span></code> for Chinese).</p>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">See <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn’s CountVectorizer docs</a>
for detailed description of the configuration parameters</p>
<p>This featurizer can be configured to use word or character n-grams, using <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> config parameter.
By default <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is set to <code class="docutils literal notranslate"><span class="pre">word</span></code> so word token counts are used as features.
If you want to use character n-grams, set <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> to <code class="docutils literal notranslate"><span class="pre">char</span></code> or <code class="docutils literal notranslate"><span class="pre">char_wb</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Option ‘char_wb’ creates character n-grams only from text inside word boundaries;
n-grams at the edges of words are padded with space.
This option can be used to create <a class="reference external" href="https://arxiv.org/abs/1810.07150">Subword Semantic Hashing</a></p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For character n-grams do not forget to increase <code class="docutils literal notranslate"><span class="pre">min_ngram</span></code> and <code class="docutils literal notranslate"><span class="pre">max_ngram</span></code> parameters.
Otherwise the vocabulary will contain only single letters</p>
</div>
<p>Handling Out-Of-Vacabulary (OOV) words:</p>
<blockquote>
<div><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Enabled only if <code class="docutils literal notranslate"><span class="pre">analyzer</span></code> is <code class="docutils literal notranslate"><span class="pre">word</span></code>.</p>
</div>
<p>Since the training is performed on limited vocabulary data, it cannot be guaranteed that during prediction
an algorithm will not encounter an unknown word (a word that were not seen during training).
In order to teach an algorithm how to treat unknown words, some words in training data can be substituted by generic word <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code>.
In this case during prediction all unknown words will be treated as this generic word <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code>.</p>
<p>For example, one might create separate intent <code class="docutils literal notranslate"><span class="pre">outofscope</span></code> in the training data containing messages of different number of <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> s and
maybe some additional general words. Then an algorithm will likely classify a message with unknown words as this intent <code class="docutils literal notranslate"><span class="pre">outofscope</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>This featurizer creates a bag-of-words representation by <strong>counting</strong> words,
so the number of <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> in the sentence might be important.</p>
<ul class="last simple">
<li><code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> set a keyword for unseen words; if training data contains <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> as words in some messages,
during prediction the words that were not seen during training will be substituted with provided <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code>;
if <code class="docutils literal notranslate"><span class="pre">OOV_token=None</span></code> (default behaviour) words that were not seen during training will be ignored during prediction time;</li>
<li><code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> set a list of words to be treated as <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> during training; if a list of words that should be treated
as Out-Of-Vacabulary is known, it can be set to <code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> instead of manually changing it in trainig data or using custom preprocessor.</li>
</ul>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Providing <code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> is optional, training data can contain <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> input manually or by custom additional preprocessor.
Unseen words will be substituted with <code class="docutils literal notranslate"><span class="pre">OOV_token</span></code> <strong>only</strong> if this token is present in the training data or <code class="docutils literal notranslate"><span class="pre">OOV_words</span></code> list is provided.</p>
</div>
</div></blockquote>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span>pipeline:
- name: &quot;intent_featurizer_count_vectors&quot;
  # whether to use word or character n-grams
  # &#39;char_wb&#39; creates character n-grams only inside word boundaries
  # n-grams at the edges of words are padded with space.
  &quot;analyzer&quot;: &#39;word&#39;,  # use &#39;char&#39; or &#39;char_wb&#39; for character
  # the parameters are taken from
  # sklearn&#39;s CountVectorizer
  # regular expression for tokens
  &quot;token_pattern&quot;: r&#39;(?u)\b\w\w+\b&#39;
  # remove accents during the preprocessing step
  &quot;strip_accents&quot;: None  # {&#39;ascii&#39;, &#39;unicode&#39;, None}
  # list of stop words
  &quot;stop_words&quot;: None  # string {&#39;english&#39;}, list, or None (default)
  # min document frequency of a word to add to vocabulary
  # float - the parameter represents a proportion of documents
  # integer - absolute counts
  &quot;min_df&quot;: 1  # float in range [0.0, 1.0] or int
  # max document frequency of a word to add to vocabulary
  # float - the parameter represents a proportion of documents
  # integer - absolute counts
  &quot;max_df&quot;: 1.0  # float in range [0.0, 1.0] or int
  # set ngram range
  &quot;min_ngram&quot;: 1  # int
  &quot;max_ngram&quot;: 1  # int
  # limit vocabulary size
  &quot;max_features&quot;: None  # int or None
  # if convert all characters to lowercase
  &quot;lowercase&quot;: true  # bool
  # handling Out-Of-Vacabulary (OOV) words
  # will be converted to lowercase if lowercase is true
  &quot;OOV_token&quot;: None  # string or None
  &quot;OOV_words&quot;: []  # list of strings
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-keyword">
<h2><a class="toc-backref" href="#id10">intent_classifier_keyword</a><a class="headerlink" href="#intent-classifier-keyword" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Simple keyword matching intent classifier.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.98343</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first last">This classifier is mostly used as a placeholder. It is able to recognize <cite>hello</cite> and
<cite>goodbye</cite> intents by searching for these keywords in the passed messages.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-mitie">
<h2><a class="toc-backref" href="#id11">intent_classifier_mitie</a><a class="headerlink" href="#intent-classifier-mitie" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE intent classifier (using a <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/examples/python/text_categorizer_pure_model.py">text categorizer</a>)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.98343</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This classifier uses MITIE to perform intent classification. The underlying classifier
is using a multi class linear SVM with a sparse linear kernel (see <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/mitielib/src/text_categorizer_trainer.cpp#L222">mitie trainer code</a>).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;intent_classifier_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-sklearn">
<h2><a class="toc-backref" href="#id12">intent_classifier_sklearn</a><a class="headerlink" href="#intent-classifier-sklearn" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">sklearn intent classifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code> and <code class="docutils literal notranslate"><span class="pre">intent_ranking</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.78343</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.1485910906220309</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;goodbye&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.08161531595656784</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">The sklearn intent classifier trains a linear SVM which gets optimized using a grid search. In addition
to other classifiers it also provides rankings of the labels that did not “win”. The spacy intent classifier
needs to be preceded by a featurizer in the pipeline. This featurizer creates the features used for the classification.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">During the training of the SVM a hyperparameter search is run to
find the best parameter set. In the config, you can specify the parameters
that will get tried</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;intent_classifier_sklearn&quot;</span>
  <span class="c1"># Specifies the list of regularization values to</span>
  <span class="c1"># cross-validate over for C-SVM.</span>
  <span class="c1"># This is used with the ``kernel`` hyperparameter in GridSearchCV.</span>
  <span class="nt">C</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">1</span><span class="p p-Indicator">,</span> <span class="nv">2</span><span class="p p-Indicator">,</span> <span class="nv">5</span><span class="p p-Indicator">,</span> <span class="nv">10</span><span class="p p-Indicator">,</span> <span class="nv">20</span><span class="p p-Indicator">,</span> <span class="nv">100</span><span class="p p-Indicator">]</span>
  <span class="c1"># Specifies the kernel to use with C-SVM.</span>
  <span class="c1"># This is used with the ``C`` hyperparameter in GridSearchCV.</span>
  <span class="nt">kernels</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;linear&quot;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-classifier-tensorflow-embedding">
<h2><a class="toc-backref" href="#id13">intent_classifier_tensorflow_embedding</a><a class="headerlink" href="#intent-classifier-tensorflow-embedding" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Embedding intent classifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first"><code class="docutils literal notranslate"><span class="pre">intent</span></code> and <code class="docutils literal notranslate"><span class="pre">intent_ranking</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;greet&quot;</span><span class="p">,</span> <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.8343</span><span class="p">},</span>
    <span class="nt">&quot;intent_ranking&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.385910906220309</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;goodbye&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.28161531595656784</span><span class="p">,</span>
            <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;restaurant_search&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">The embedding intent classifier embeds user inputs and intent labels into the same space. Supervised embeddings are
trained by maximizing similarity between them. This algorithm is based on
the starspace idea from: <a class="reference external" href="https://arxiv.org/abs/1709.03856">https://arxiv.org/abs/1709.03856</a>. However, in this implementation
the <code class="docutils literal notranslate"><span class="pre">mu</span></code> parameter is treated differently and additional hidden layers are added together with dropout.
This algorithm also provides similarity rankings of the labels that did not “win”.</p>
<p>The embedding intent classifier needs to be preceded by a featurizer in the pipeline.
This featurizer creates the features used for the embeddings.
It is recommended to use <code class="docutils literal notranslate"><span class="pre">intent_featurizer_count_vectors</span></code> that can be optionally preceded
by <code class="docutils literal notranslate"><span class="pre">nlp_spacy</span></code> and <code class="docutils literal notranslate"><span class="pre">tokenizer_spacy</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If during prediction time a message contains <strong>only</strong> words unseen during training,
and no Out-Of-Vacabulary preprocessor was used,
empty intent <code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code> is predicted with confidence <code class="docutils literal notranslate"><span class="pre">0.0</span></code>.</p>
</div>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">If you want to split intents into multiple labels, e.g. for predicting multiple intents or for
modeling hierarchical intent structure, use these flags:</p>
<ul class="simple">
<li><dl class="first docutils">
<dt>tokenization of intent labels:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">intent_tokenization_flag</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm will split the intent labels into tokens and use bag-of-words representations for them, default <code class="docutils literal notranslate"><span class="pre">false</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">intent_split_symbol</span></code> sets the delimiter string to split the intent labels, default <code class="docutils literal notranslate"><span class="pre">_</span></code>.</li>
</ul>
</dd>
</dl>
</li>
</ul>
<dl class="docutils">
<dt>The algorithm also has hyperparameters to control:</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>neural network’s architecture:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_a</span></code> sets a list of hidden layer sizes before the embedding layer for user inputs, the number of hidden layers is equal to the length of the list</li>
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_b</span></code> sets a list of hidden layer sizes before the embedding layer for intent labels, the number of hidden layers is equal to the length of the list</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>training:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> sets the number of training examples in one forward/backward pass, the higher the batch size, the more memory space you’ll need;</li>
<li><code class="docutils literal notranslate"><span class="pre">epochs</span></code> sets the number of times the algorithm will see training data, where <code class="docutils literal notranslate"><span class="pre">one</span> <span class="pre">epoch</span></code> = one forward pass and one backward pass of all the training examples;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>embedding:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">embed_dim</span></code> sets the dimension of embedding space;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> controls how similar the algorithm should try to make embedding vectors for correct intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> controls maximum negative similarity for incorrect intents;</li>
<li><code class="docutils literal notranslate"><span class="pre">similarity_type</span></code> sets the type of the similarity, it should be either <code class="docutils literal notranslate"><span class="pre">cosine</span></code> or <code class="docutils literal notranslate"><span class="pre">inner</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">num_neg</span></code> sets the number of incorrect intent labels, the algorithm will minimize their similarity to the user input during training;</li>
<li><code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm only minimizes maximum similarity over incorrect intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">random_seed</span></code> (None or int) An integer sets the random seed for numpy and tensorflow, so that the random initialisation is always the same and produces the same training result</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>regularization:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">C2</span></code> sets the scale of L2 regularization</li>
<li><code class="docutils literal notranslate"><span class="pre">C_emb</span></code> sets the scale of how important is to minimize the maximum similarity between embeddings of different intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate</span></code> sets the dropout rate, it should be between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">droprate=0.1</span></code> would drop out <code class="docutils literal notranslate"><span class="pre">10%</span></code> of input units;</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For <code class="docutils literal notranslate"><span class="pre">cosine</span></code> similarity <code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> should be between <code class="docutils literal notranslate"><span class="pre">-1</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There is an option to use linearly increasing batch size. The idea comes from <a class="reference external" href="https://arxiv.org/abs/1711.00489">https://arxiv.org/abs/1711.00489</a>.
In order to do it pass a list to <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">[64,</span> <span class="pre">256]</span></code> (default behaviour).
If constant <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is required, pass an <code class="docutils literal notranslate"><span class="pre">int</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">64</span></code>.</p>
</div>
<p>In the config, you can specify these parameters:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;intent_classifier_tensorflow_embedding&quot;</span>
  <span class="c1"># nn architecture</span>
  <span class="s">&quot;hidden_layers_sizes_a&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">256</span><span class="p p-Indicator">,</span> <span class="nv">128</span><span class="p p-Indicator">]</span>
  <span class="s">&quot;hidden_layers_sizes_b&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[]</span>
  <span class="s">&quot;batch_size&quot;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">64</span><span class="p p-Indicator">,</span> <span class="nv">256</span><span class="p p-Indicator">]</span>
  <span class="s">&quot;epochs&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">300</span>
  <span class="c1"># embedding parameters</span>
  <span class="s">&quot;embed_dim&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
  <span class="s">&quot;mu_pos&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>  <span class="c1"># should be 0.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
  <span class="s">&quot;mu_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">-0.4</span>  <span class="c1"># should be -1.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
  <span class="s">&quot;similarity_type&quot;</span><span class="p p-Indicator">:</span> <span class="s">&quot;cosine&quot;</span>  <span class="c1"># string &#39;cosine&#39; or &#39;inner&#39;</span>
  <span class="s">&quot;num_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
  <span class="s">&quot;use_max_sim_neg&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>  <span class="c1"># flag which loss function to use</span>
  <span class="s">&quot;random_seed&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span> <span class="c1"># set to any int to generate a reproducible training result</span>
  <span class="c1"># regularization</span>
  <span class="s">&quot;C2&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.002</span>
  <span class="s">&quot;C_emb&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>
  <span class="s">&quot;droprate&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.2</span>
  <span class="c1"># flag for tokenizing intents</span>
  <span class="s">&quot;intent_tokenization_flag&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="s">&quot;intent_split_symbol&quot;</span><span class="p p-Indicator">:</span> <span class="s">&quot;_&quot;</span>
  <span class="c1"># visualization of accuracy</span>
  <span class="s">&quot;evaluate_every_num_epochs&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>  <span class="c1"># small values may hurt performance</span>
  <span class="s">&quot;evaluate_on_num_examples&quot;</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>  <span class="c1"># large values may hurt performance</span>
</pre></div>
</div>
<div class="last admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Parameter <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> is set to a negative value to mimic the original
starspace algorithm in the case <code class="docutils literal notranslate"><span class="pre">mu_neg</span> <span class="pre">=</span> <span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span> <span class="pre">=</span> <span class="pre">False</span></code>.
See <a class="reference external" href="https://arxiv.org/abs/1709.03856">starspace paper</a> for details.</p>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="intent-entity-featurizer-regex">
<h2><a class="toc-backref" href="#id14">intent_entity_featurizer_regex</a><a class="headerlink" href="#intent-entity-featurizer-regex" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">regex feature creation to support intent and entity classification</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><code class="docutils literal notranslate"><span class="pre">text_features</span></code> and <code class="docutils literal notranslate"><span class="pre">tokens.pattern</span></code></td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">During training, the regex intent featurizer creates a list of <cite>regular expressions</cite> defined in the training data format.
For each regex, a feature will be set marking whether this expression was found in the input, which will later be fed into intent classifier / entity
extractor to simplify classification (assuming the classifier has learned during the training phase, that this set
feature indicates a certain intent). Regex features for entity extraction are currently only supported by the
<code class="docutils literal notranslate"><span class="pre">ner_crf</span></code> component!
.. note:: There needs to be a tokenizer previous to this featurizer in the pipeline!</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-whitespace">
<h2><a class="toc-backref" href="#id15">tokenizer_whitespace</a><a class="headerlink" href="#tokenizer-whitespace" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">Tokenizer using whitespaces as a separator</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">Creates a token for every whitespace separated character sequence. Can be used to define tokens for the MITIE entity
extractor.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-jieba">
<h2><a class="toc-backref" href="#id16">tokenizer_jieba</a><a class="headerlink" href="#tokenizer-jieba" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using Jieba for Chinese language</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates tokens using the Jieba tokenizer specifically for Chinese
language. For language other than Chinese, Jieba will work as
<code class="docutils literal notranslate"><span class="pre">tokenizer_whitespace</span></code>. Can be used to define tokens for the
MITIE entity extractor. Make sure to install Jieba, <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">jieba</span></code>.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">User’s custom dictionary files can be auto loaded by specific the files’ directory path via <code class="docutils literal notranslate"><span class="pre">dictionary_path</span></code></p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;tokenizer_jieba&quot;</span>
  <span class="nt">dictionary_path</span><span class="p">:</span> <span class="s">&quot;path/to/custom/dictionary/dir&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>If the <code class="docutils literal notranslate"><span class="pre">dictionary_path</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code> (the default), then no custom dictionary will be used.</p>
</div>
<div class="section" id="tokenizer-mitie">
<h2><a class="toc-backref" href="#id17">tokenizer_mitie</a><a class="headerlink" href="#tokenizer-mitie" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Tokenizer using MITIE</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">nothing</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">Creates tokens using the MITIE tokenizer. Can be used to define
tokens for the MITIE entity extractor.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;tokenizer_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="tokenizer-spacy">
<h2><a class="toc-backref" href="#id18">tokenizer_spacy</a><a class="headerlink" href="#tokenizer-spacy" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body">Tokenizer using spacy</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body">nothing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body">Creates tokens using the spacy tokenizer. Can be used to define
tokens for the MITIE entity extractor.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-mitie">
<h2><a class="toc-backref" href="#id19">ner_mitie</a><a class="headerlink" href="#ner-mitie" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">MITIE entity extraction (using a <a class="reference external" href="https://github.com/mit-nlp/MITIE/blob/master/mitielib/src/ner_trainer.cpp">mitie ner trainer</a>)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_mitie&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This uses the MITIE entitiy extraction to find entities in a message. The underlying classifier
is using a multi class linear SVM with a sparse linear kernel and custom features.
The MITIE component does not provide entity confidence values.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;ner_mitie&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-spacy">
<h2><a class="toc-backref" href="#id20">ner_spacy</a><a class="headerlink" href="#ner-spacy" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">spacy entity extraction</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_spacy&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first last">Using spacy this component predicts the entities of a message. spacy uses a statistical BILOU transition model.
As of now, this component can only use the spacy builtin entity extraction models and can not be retrained.
This extractor does not provide any confidence scores.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-synonyms">
<h2><a class="toc-backref" href="#id21">ner_synonyms</a><a class="headerlink" href="#ner-synonyms" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Maps synonymous entity values to the same value.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">modifies existing entities that previous entity extraction components found</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Description:</th><td class="field-body"><p class="first">If the training data contains defined synonyms (by using the <code class="docutils literal notranslate"><span class="pre">value</span></code> attribute on the entity examples).
this component will make sure that detected entity values will be mapped to the same value. For example,
if your training data contains the following examples:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span>
  <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I moved to New York City&quot;</span><span class="p">,</span>
  <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="s2">&quot;inform_relocation&quot;</span><span class="p">,</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;nyc&quot;</span><span class="p">,</span>
                <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span>
                <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
                <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
               <span class="p">}]</span>
<span class="p">},</span>
<span class="p">{</span>
  <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;I got a new flat in NYC.&quot;</span><span class="p">,</span>
  <span class="nt">&quot;intent&quot;</span><span class="p">:</span> <span class="s2">&quot;inform_relocation&quot;</span><span class="p">,</span>
  <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;nyc&quot;</span><span class="p">,</span>
                <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span>
                <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
               <span class="p">}]</span>
<span class="p">}]</span>
</pre></div>
</div>
<p class="last">this component will allow you to map the entities <code class="docutils literal notranslate"><span class="pre">New</span> <span class="pre">York</span> <span class="pre">City</span></code> and <code class="docutils literal notranslate"><span class="pre">NYC</span></code> to <code class="docutils literal notranslate"><span class="pre">nyc</span></code>. The entitiy
extraction will return <code class="docutils literal notranslate"><span class="pre">nyc</span></code> even though the message contains <code class="docutils literal notranslate"><span class="pre">NYC</span></code>. When this component changes an
exisiting entity, it appends itself to the processor list of this entity.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-crf">
<h2><a class="toc-backref" href="#id22">ner_crf</a><a class="headerlink" href="#ner-crf" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">conditional random field entity extraction</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;New York City&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                  <span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">0.874</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_crf&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">This component implements conditional random fields to do named entity recognition.
CRFs can be thought of as an undirected Markov chain where the time steps are words
and the states are entity classes. Features of the words (capitalisation, POS tagging,
etc.) give probabilities to certain entity classes, as are transitions between
neighbouring entity tags: the most likely set of tags is then calculated and returned.
If POS features are used (pos or pos2), spaCy has to be installed.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><div class="first last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;ner_crf&quot;</span>
  <span class="c1"># The features are a ``[before, word, after]`` array with</span>
  <span class="c1"># before, word, after holding keys about which</span>
  <span class="c1"># features to use for each word, for example, ``&quot;title&quot;``</span>
  <span class="c1"># in array before will have the feature</span>
  <span class="c1"># &quot;is the preceding word in title case?&quot;.</span>
  <span class="c1"># Available features are:</span>
  <span class="c1"># ``low``, ``title``, ``suffix5``, ``suffix3``, ``suffix2``,</span>
  <span class="c1"># ``suffix1``, ``pos``, ``pos2``, ``prefix5``, ``prefix2``,</span>
  <span class="c1"># ``bias``, ``upper`` and ``digit``</span>
  <span class="nt">features</span><span class="p">:</span> <span class="p p-Indicator">[[</span><span class="s">&quot;low&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;title&quot;</span><span class="p p-Indicator">],</span> <span class="p p-Indicator">[</span><span class="s">&quot;bias&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;suffix3&quot;</span><span class="p p-Indicator">],</span> <span class="p p-Indicator">[</span><span class="s">&quot;upper&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;pos&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;pos2&quot;</span><span class="p p-Indicator">]]</span>

  <span class="c1"># The flag determines whether to use BILOU tagging or not. BILOU</span>
  <span class="c1"># tagging is more rigorous however</span>
  <span class="c1"># requires more examples per entity. Rule of thumb: use only</span>
  <span class="c1"># if more than 100 examples per entity.</span>
  <span class="nt">BILOU_flag</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="nt">max_iterations</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="c1"># Specifies the L1 regularization coefficient.</span>
  <span class="nt">L1_c</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>

  <span class="c1"># This is the value given to sklearn_crfcuite.CRF tagger before training.</span>
  <span class="c1"># Specifies the L2 regularization coefficient.</span>
  <span class="nt">L2_c</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ner-duckling-http">
<span id="id2"></span><h2><a class="toc-backref" href="#id23">ner_duckling_http</a><a class="headerlink" href="#ner-duckling-http" title="Permalink to this headline">¶</a></h2>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Short:</th><td class="field-body"><p class="first">Duckling lets you extract common entities like dates,
amounts of money, distances, and others in a number of languages.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Outputs:</th><td class="field-body"><p class="first">appends <code class="docutils literal notranslate"><span class="pre">entities</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Output-Example:</th><td class="field-body"><div class="first highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;entities&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="nt">&quot;end&quot;</span><span class="p">:</span> <span class="mi">53</span><span class="p">,</span>
                  <span class="nt">&quot;entity&quot;</span><span class="p">:</span> <span class="s2">&quot;time&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">48</span><span class="p">,</span>
                  <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="s2">&quot;2017-04-10T00:00:00.000+02:00&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;confidence&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                  <span class="nt">&quot;extractor&quot;</span><span class="p">:</span> <span class="s2">&quot;ner_duckling_http&quot;</span><span class="p">}]</span>
<span class="p">}</span>
</pre></div>
</div>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Description:</th><td class="field-body"><p class="first">To use this component you need to run a duckling server. The easiest
option is to spin up a docker container using
<code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">-p</span> <span class="pre">8000:8000</span> <span class="pre">rasa/duckling</span></code>.</p>
<p>Alternatively, you can install duckling directly on your
<a class="reference external" href="https://github.com/facebook/duckling#quickstart">machine and start the server</a>.</p>
<p>Duckling allows to recognize dates, numbers, distances and other structured entities
and normalizes them (for a reference of all available entities
see <a class="reference external" href="https://duckling.wit.ai/#getting-started">the duckling documentation</a>).
Please be aware that duckling tries to extract as many entity types as possible without
providing a ranking. For example, if you specify both <code class="docutils literal notranslate"><span class="pre">number</span></code> and <code class="docutils literal notranslate"><span class="pre">time</span></code> as dimensions
for the duckling component, the component will extract two entities: <code class="docutils literal notranslate"><span class="pre">10</span></code> as a number and
<code class="docutils literal notranslate"><span class="pre">in</span> <span class="pre">10</span> <span class="pre">minutes</span></code> as a time from the text <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">will</span> <span class="pre">be</span> <span class="pre">there</span> <span class="pre">in</span> <span class="pre">10</span> <span class="pre">minutes</span></code>. In such a
situation, your application would have to decide which entity type is be the correct one.
The extractor will always return <cite>1.0</cite> as a confidence, as it is a rule
based system.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Configuration:</th><td class="field-body"><p class="first">Configure which dimensions, i.e. entity types, the duckling component
to extract. A full list of available dimensions can be found in
the <a class="reference external" href="https://duckling.wit.ai/">duckling documentation</a>.</p>
<div class="last highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pipeline</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="s">&quot;ner_duckling_http&quot;</span>
  <span class="c1"># url of the running duckling server</span>
  <span class="nt">url</span><span class="p">:</span> <span class="s">&quot;http://localhost:8000&quot;</span>
  <span class="c1"># dimensions to extract</span>
  <span class="nt">dimensions</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;time&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;number&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;amount-of-money&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;distance&quot;</span><span class="p p-Indicator">]</span>
  <span class="c1"># allows you to configure the locale, by default the language is</span>
  <span class="c1"># used</span>
  <span class="nt">locale</span><span class="p">:</span> <span class="s">&quot;de_DE&quot;</span>
  <span class="c1"># if not set the default timezone of Duckling is going to be used</span>
  <span class="c1"># needed to calculate dates from relative expressions like &quot;tomorrow&quot;</span>
  <span class="nt">timezone</span><span class="p">:</span> <span class="s">&quot;Europe/Berlin&quot;</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<div class="section" id="have-questions-or-feedback">
<h3><a class="toc-backref" href="#id24">Have questions or feedback?</a><a class="headerlink" href="#have-questions-or-feedback" title="Permalink to this headline">¶</a></h3>
<p>We have a very active support community on <a class="reference external" href="https://forum.rasa.com">Rasa Community Forum</a>
that is happy to help you with your questions. If you have any feedback for us or a specific
suggestion for improving the docs, feel free to share it by creating an issue on Rasa NLU
<a class="reference external" href="https://github.com/RasaHQ/rasa_nlu">GitHub repository</a>.</p>
</div>
</div>
</div>


	    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	    <script type="text/javascript"> docsearch({
	     apiKey: '1f9e0efb89e98543f6613a60f847b176',
	     indexName: 'rasa',
	     inputSelector: 'body > div.nav-top > .nav-container > .nav > input',
	     debug: false // Set debug to true if you want to inspect the dropdown
	    });
	    </script>
          </div>

          <div class="footer">

            <div class="social">
              <a href="https://github.com/RasaHQ" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
              <a href="https://stackoverflow.com/search?q=rasa" target="_blank" title="Stack Overflow"><i class="fab fa-stack-overflow"></i></a>
              <a href="https://www.youtube.com/channel/UCJ0V6493mLvqdiVwOKWBODQ" target="_blank" title="YouTube"><i class="fab fa-youtube"></i></a>
              <a href="https://twitter.com/rasa_hq" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
            </div>

            <div class="copyright small">
            &copy;2018, Rasa Technologies GmbH | <a href="https://rasa.com/imprint/" target="_blank">Imprint</a> | <a href="https://rasa.com/privacy-policy/" target="_blank">Privacy Policy</a>
            
            </div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>

    

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag(...arguments) {
      dataLayer.push(...arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-87333416-1', {
      'anonymize_ip': true,
    });
  </script>
  <script src="https://rasa.com/assets/js/js.cookies.js"></script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script type="opt-in" data-name="googleanalytics" data-type="text/javascript" data-src="https://www.googletagmanager.com/gtag/js?id=UA-87333416-1"></script>
  <script type="opt-in" data-name="googleanalytics" data-type="text/javascript" data-src="https://rasa.com/assets/js/userId.js"></script>

  <script type="text/javascript">
    var clipboard = new ClipboardJS('.copyable');
    clipboard.on('success', function(e) {
      gtag('event', e.action, {
        'event_category': 'code',
        'event_label': e.text
      });
      const id = e.text.replace(' ','-');
      document.getElementById(id).classList.add('visible');
      setTimeout(function(){
        document.getElementById(id).classList.remove('visible');},
        800
      );
    });
    clipboard.on('error', function(e) {
      console.log(e);
    });
  </script>

  <!-- onsite anchor fix (otherwise anchors scroll to far) -->
  <script>
    /* Adapted from https://stackoverflow.com/a/13067009/1906073 */
    (function(document, history, location) {
      var HISTORY_SUPPORT = !!(history && history.pushState);

      var anchorScrolls = {
        ANCHOR_REGEX: /^#[^ ]+$/,
        OFFSET_HEIGHT_PX: 66,

        /**
         * Establish events, and fix initial scroll position if a hash is provided.
         */
        init: function() {
          this.scrollToCurrent();
          $(window).on('hashchange', $.proxy(this, 'scrollToCurrent'));
          $('body').on('click', 'a', $.proxy(this, 'delegateAnchors'));
        },

        /**
         * Return the offset amount to deduct from the normal scroll position.
         * Modify as appropriate to allow for dynamic calculations
         */
        getFixedOffset: function() {
          return this.OFFSET_HEIGHT_PX;
        },

        /**
         * If the provided href is an anchor which resolves to an element on the
         * page, scroll to it.
         * @param  {String} href
         * @return {Boolean} - Was the href an anchor.
         */
        scrollIfAnchor: function(href, pushToHistory) {
          var match, anchorOffset;

          if(!this.ANCHOR_REGEX.test(href)) {
            return false;
          }

          match = document.getElementById(href.slice(1));

          if(match) {
            anchorOffset = $(match).offset().top - this.getFixedOffset();
            $('html, body').animate({ scrollTop: anchorOffset});

            // Add the state to history as-per normal anchor links
            if(HISTORY_SUPPORT && pushToHistory) {
              history.pushState({}, document.title, location.pathname + href);
            }
          }

          return !!match;
        },

        /**
         * Attempt to scroll to the current location's hash.
         */
        scrollToCurrent: function(e) {
          if(this.scrollIfAnchor(window.location.hash) && e) {
            e.preventDefault();
          }
        },

        /**
         * If the click event's target was an anchor, fix the scroll position.
         */
        delegateAnchors: function(e) {
          var elem = e.target;

          if(this.scrollIfAnchor(elem.getAttribute('href'), true)) {
            e.preventDefault();
          }
        }
      };

      $(document).ready($.proxy(anchorScrolls, 'init'));
    })(window.document, window.history, window.location);

  </script>
  </body>
</html>